{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import analytiq_data as ad\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.common.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MONGODB_URI environment variable\n",
    "os.environ[\"MONGODB_URI\"] = \"mongodb://localhost:27017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qP8xDKSfu6Ede7pbEmUWc6I6ii7sOAHr\n"
     ]
    }
   ],
   "source": [
    "analytiq_client = ad.common.get_analytiq_client(env=\"test\")\n",
    "\n",
    "llm_key = await ad.llm.get_llm_key(analytiq_client, llm_provider=\"mistral\")\n",
    "print(llm_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('67fb329275436ea808f0c0b5', 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_id = \"6795345439604beca2b2808d\"\n",
    "prompt_id, version = await ad.common.get_prompt_id(analytiq_client, \"cv\", org_id)\n",
    "prompt_id, version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'688ae98796b08198647ef46d'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_rev_id = await ad.common.get_prompt_rev_id(analytiq_client, prompt_id, version)\n",
    "prompt_rev_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_rev_id = \"68926f54b175d0e0ff51b11c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_id = \"687c5bd2eecf1be4639ea6d0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 17:03:25,192 - analytiq_data.llm.models - INFO - Checking if groq/deepseek-r1-distill-llama-70b is a chat model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'groq/deepseek-r1-distill-llama-70b'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await ad.llm.get_llm_model(analytiq_client, prompt_rev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the AWS credentials in the env to avoid using them\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\"\n",
    "os.environ[\"AWS_REGION_NAME\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 17:19:43,741 - analytiq_data.llm.llm - INFO - Running new LLM analysis for document_id: 687c5bd2eecf1be4639ea6d0, prompt_rev_id: 68926f54b175d0e0ff51b11c\n",
      "2025-08-05 17:19:43,743 - analytiq_data.payments.spu - INFO - Checking spu limits for org_id: 684d12aafb34e85859f12712\n",
      "2025-08-05 17:19:43,743 - analytiq_data.llm.models - INFO - Checking if groq/deepseek-r1-distill-llama-70b is a chat model\n",
      "2025-08-05 17:19:43,744 - analytiq_data.llm.llm - INFO - LLM model: groq/deepseek-r1-distill-llama-70b, provider: groq, api_key: gsk_nrtxcOehMGXc********\n",
      "2025-08-05 17:19:43,748 - analytiq_data.llm.llm - INFO - Attaching OCR-only to prompt 68926f54b175d0e0ff51b11c\n",
      "2025-08-05 17:19:43,749 - analytiq_data.llm.llm - INFO - Response format: {'type': 'json_schema', 'json_schema': {'name': 'document_extraction', 'schema': {'type': 'object', 'properties': {'document_type': {'type': 'string', 'description': 'Type of insurance application. One of: personal, commercial, unknown. Do not leave empty.'}, 'clearance_search_fields': {'type': 'object', 'properties': {'insured_name': {'type': 'object', 'properties': {'full_name': {'type': 'string', 'description': 'Complete name as it appears in the document'}, 'first_name': {'type': 'string', 'description': 'First name if individual'}, 'middle_name': {'type': 'string', 'description': 'Middle name or initial if present'}, 'last_name': {'type': 'string', 'description': 'Last name if individual'}, 'entity_type': {'type': 'string', 'description': 'Type of entity'}, 'confidence': {'type': 'integer', 'description': 'Confidence score for this field, on a scale from 0 to 10.'}}, 'additionalProperties': False, 'required': ['full_name', 'first_name', 'middle_name', 'last_name', 'entity_type', 'confidence'], 'description': 'Name of the applicant/insured (may be individual, trust, or business)'}, 'mailing_address': {'type': 'object', 'properties': {'street_address': {'type': 'string', 'description': 'Street number and name'}, 'street_address_2': {'type': 'string', 'description': 'Apartment, suite, unit, etc.'}, 'city': {'type': 'string', 'description': 'City name'}, 'state': {'type': 'string', 'description': 'State abbreviation or full name'}, 'zip_code': {'type': 'string', 'description': 'ZIP code (5 or 9 digits)'}, 'confidence': {'type': 'integer', 'description': 'Confidence score for this field, on a scale from 0 to 10.'}}, 'additionalProperties': False, 'required': ['street_address', 'street_address_2', 'city', 'state', 'zip_code', 'confidence'], 'description': 'Mailing address of the applicant/insured (not property address)'}}, 'additionalProperties': False, 'required': ['insured_name', 'mailing_address'], 'description': 'Primary fields required for clearance search'}, 'additional_clearance_fields': {'type': 'object', 'properties': {'date_of_birth': {'type': 'string', 'description': 'Date of birth if individual.'}, 'occupation': {'type': 'string', 'description': 'Occupation of insured if provided.'}, 'phone_number': {'type': 'string', 'description': 'Primary phone number'}, 'email': {'type': 'string', 'description': 'Email address if provided'}}, 'additionalProperties': False, 'required': ['date_of_birth', 'occupation', 'phone_number', 'email'], 'description': 'Additional fields that may be needed for clearance'}, 'document_quality_indicators': {'type': 'object', 'properties': {'is_handwritten': {'type': 'boolean', 'description': 'Contains handwritten portions'}, 'is_scanned': {'type': 'boolean', 'description': 'Appears to be a scanned document'}, 'has_corrections': {'type': 'boolean', 'description': 'Contains crossed out or corrected information'}, 'quality_issues': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of quality issues encountered'}}, 'additionalProperties': False, 'required': ['is_handwritten', 'is_scanned', 'has_corrections', 'quality_issues'], 'description': 'Indicators of document quality and extraction challenges'}, 'human_review_guidance': {'type': 'object', 'properties': {'review_required': {'type': 'boolean', 'description': 'Whether human review is required'}, 'confidence_score': {'type': 'integer', 'description': 'Overall confidence score for the extraction, on a scale from 0 to 10.'}, 'extraction_warnings': {'type': 'string', 'description': 'List of warnings or issues during extraction'}}, 'additionalProperties': False, 'required': ['review_required', 'confidence_score', 'extraction_warnings'], 'description': 'Specific guidance for human review if needed'}, 'review_reasons': {'type': 'array', 'items': {'type': 'object', 'properties': {'field': {'type': 'string', 'description': 'Field that needs to be reviewed'}, 'reason': {'type': 'string', 'description': 'Reason to review'}, 'suggested_action': {'type': 'string', 'description': 'Suggested corrective actions'}}, 'additionalProperties': False, 'required': ['field', 'reason', 'suggested_action']}, 'description': 'Reasons why review is needed'}}, 'required': ['document_type', 'clearance_search_fields', 'additional_clearance_fields', 'document_quality_indicators', 'human_review_guidance', 'review_reasons'], 'additionalProperties': False}, 'strict': True}}\n",
      "2025-08-05 17:19:43,749 - analytiq_data.llm.llm - INFO - Disabling response_format for Groq provider\n",
      "\u001b[92m17:19:43 - LiteLLM:INFO\u001b[0m: utils.py:2826 - \n",
      "LiteLLM completion() model= deepseek-r1-distill-llama-70b; provider = groq\n",
      "2025-08-05 17:19:43,750 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= deepseek-r1-distill-llama-70b; provider = groq\n",
      "2025-08-05 17:19:46,743 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:19:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: groq/deepseek-r1-distill-llama-70b\n",
      "2025-08-05 17:19:46,747 - LiteLLM - INFO - selected model name for cost calculation: groq/deepseek-r1-distill-llama-70b\n",
      "2025-08-05 17:19:46,749 - analytiq_data.payments.spu - INFO - Recording 1 spu usage for org_id: 684d12aafb34e85859f12712\n",
      "2025-08-05 17:19:46,751 - analytiq_data.llm.llm - INFO - LLM response: ModelResponse(id='chatcmpl-6dbe0d7e-0ba3-41eb-a3e6-6dd1d911b16a', created=1754428786, model='deepseek-r1-distill-llama-70b', object='chat.completion', system_fingerprint='fp_1bbe7845ec', choices=[Choices(finish_reason='stop', index=0, message=Message(content='<think>\\nAlright, I need to extract the applicant\\'s name and mailing address from this insurance document. Let me go through the text step by step.\\n\\nFirst, I\\'ll look for sections labeled \"Applicant Information\" or similar. I see \"APPLICANT\\'S NAME AND MAILING ADDRESS\" near the top. The name listed there is \"Susan a Boucher for life.\" That seems a bit unusual, but I\\'ll take it as is since it\\'s the applicant\\'s name.\\n\\nNext, for the mailing address, I notice two addresses: \"51 Isabella ave\" and \"941 PARK AVE / Providence, RI 02908\" and \"CRANSTON RI 02910.\" I need to determine which one is the mailing address. The section \"MAIL POLICY TO:\" is mentioned later, and it has \"BILL APPLICANT\" checked, which suggests that the mailing address should be where the applicant receives correspondence. \\n\\nLooking back, \"51 Isabella ave\" is listed under \"Ashley M Gilbert,\" which might be an agent or another contact. The address \"941 PARK AVE, Providence, RI 02908\" is under the applicant\\'s name section, so that\\'s likely the mailing address. However, there\\'s also a \"CRANSTON RI 02908\" mentioned, but it\\'s not clear if that\\'s part of the same address or a different one. To be safe, I\\'ll include both street lines in street_address_2.\\n\\nThe quality of the document seems mixed. Some parts are typed, but there are handwritten corrections, like \"Susan a Boucher\" which might be a typo or a correction. The confidence score for the name is a bit lower because of the unusual formatting, so I\\'ll give it a 7. The address has some ambiguity with two possible locations, so confidence is also a 7.\\n\\nI don\\'t see any critical fields missing, but the ambiguity in the address makes me recommend a human review to confirm the correct mailing address.\\n</think>\\n\\n```json\\n{\\n  \"applicant_name\": {\\n    \"value\": \"Susan a Boucher for life\",\\n    \"confidence_score\": 7,\\n    \"source_location\": \"Page 1\",\\n    \"quality_issues\": \"Handwritten corrections, unusual name format\",\\n    \"human_review_recommended\": true\\n  },\\n  \"mailing_address\": {\\n    \"street_address_1\": \"941 PARK AVE\",\\n    \"street_address_2\": \"51 Isabella ave\",\\n    \"city\": \"Providence\",\\n    \"state\": \"RI\",\\n    \"zip_code\": \"02908\",\\n    \"confidence_score\": 7,\\n    \"source_location\": \"Page 1\",\\n    \"quality_issues\": \"Multiple addresses present, ambiguity in address type\",\\n    \"human_review_recommended\": true\\n  }\\n}\\n```', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=576, prompt_tokens=4168, total_tokens=4744, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.196410478, prompt_time=0.386593098, completion_time=2.169855246, total_time=2.556448344), usage_breakdown=None, x_groq={'id': 'req_01k1y1nfa4e27txq2b7p3q0mv7'}, service_tier='on_demand')\n",
      "2025-08-05 17:19:46,752 - analytiq_data.llm.llm - INFO - LLM response content: <think>\n",
      "Alright, I need to extract the applicant's name and mailing address from this insurance document. Let me go through the text step by step.\n",
      "\n",
      "First, I'll look for sections labeled \"Applicant Information\" or similar. I see \"APPLICANT'S NAME AND MAILING ADDRESS\" near the top. The name listed there is \"Susan a Boucher for life.\" That seems a bit unusual, but I'll take it as is since it's the applicant's name.\n",
      "\n",
      "Next, for the mailing address, I notice two addresses: \"51 Isabella ave\" and \"941 PARK AVE / Providence, RI 02908\" and \"CRANSTON RI 02910.\" I need to determine which one is the mailing address. The section \"MAIL POLICY TO:\" is mentioned later, and it has \"BILL APPLICANT\" checked, which suggests that the mailing address should be where the applicant receives correspondence. \n",
      "\n",
      "Looking back, \"51 Isabella ave\" is listed under \"Ashley M Gilbert,\" which might be an agent or another contact. The address \"941 PARK AVE, Providence, RI 02908\" is under the applicant's name section, so that's likely the mailing address. However, there's also a \"CRANSTON RI 02908\" mentioned, but it's not clear if that's part of the same address or a different one. To be safe, I'll include both street lines in street_address_2.\n",
      "\n",
      "The quality of the document seems mixed. Some parts are typed, but there are handwritten corrections, like \"Susan a Boucher\" which might be a typo or a correction. The confidence score for the name is a bit lower because of the unusual formatting, so I'll give it a 7. The address has some ambiguity with two possible locations, so confidence is also a 7.\n",
      "\n",
      "I don't see any critical fields missing, but the ambiguity in the address makes me recommend a human review to confirm the correct mailing address.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"applicant_name\": {\n",
      "    \"value\": \"Susan a Boucher for life\",\n",
      "    \"confidence_score\": 7,\n",
      "    \"source_location\": \"Page 1\",\n",
      "    \"quality_issues\": \"Handwritten corrections, unusual name format\",\n",
      "    \"human_review_recommended\": true\n",
      "  },\n",
      "  \"mailing_address\": {\n",
      "    \"street_address_1\": \"941 PARK AVE\",\n",
      "    \"street_address_2\": \"51 Isabella ave\",\n",
      "    \"city\": \"Providence\",\n",
      "    \"state\": \"RI\",\n",
      "    \"zip_code\": \"02908\",\n",
      "    \"confidence_score\": 7,\n",
      "    \"source_location\": \"Page 1\",\n",
      "    \"quality_issues\": \"Multiple addresses present, ambiguity in address type\",\n",
      "    \"human_review_recommended\": true\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m llm_result = \u001b[38;5;28;01mawait\u001b[39;00m ad.llm.run_llm(analytiq_client,\n\u001b[32m      2\u001b[39m                                   document_id=document_id,\n\u001b[32m      3\u001b[39m                                   prompt_rev_id=prompt_rev_id,\n\u001b[32m      4\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"bedrock/anthropic.claude-3-7-sonnet-20250219-v1:0\",\u001b[39;00m\n\u001b[32m      5\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\u001b[39;00m\n\u001b[32m      6\u001b[39m                                   llm_model=\u001b[33m\"\u001b[39m\u001b[33mgroq/deepseek-r1-distill-llama-70b\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"gemini/gemini-2.0-flash\",\u001b[39;00m\n\u001b[32m      8\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"gemini/gemini-2.5-flash-preview-05-20\",\u001b[39;00m\n\u001b[32m      9\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"gemini/gemini-2.5-flash-preview-tts\",\u001b[39;00m\n\u001b[32m     10\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"azure_ai/deepseek-v3\",\u001b[39;00m\n\u001b[32m     11\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"gpt-4o-mini\",\u001b[39;00m\n\u001b[32m     12\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"gpt-4o-2024-08-06\",\u001b[39;00m\n\u001b[32m     13\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"claude-3-5-sonnet\",\u001b[39;00m\n\u001b[32m     14\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"mistral/mistral-large-latest\",\u001b[39;00m\n\u001b[32m     15\u001b[39m                                   \u001b[38;5;66;03m#llm_model=\"mistral/open-mixtral-8x22b\",\u001b[39;00m\n\u001b[32m     16\u001b[39m                                   force=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     17\u001b[39m llm_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:108\u001b[39m, in \u001b[36mrun_llm\u001b[39m\u001b[34m(analytiq_client, document_id, prompt_rev_id, llm_model, force)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/json/decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    341\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m     end = _w(s, end).end()\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/json/decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    361\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:19:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: groq/deepseek-r1-distill-llama-70b\n",
      "2025-08-05 17:19:46,805 - LiteLLM - INFO - selected model name for cost calculation: groq/deepseek-r1-distill-llama-70b\n"
     ]
    }
   ],
   "source": [
    "llm_result = await ad.llm.run_llm(analytiq_client,\n",
    "                                  document_id=document_id,\n",
    "                                  prompt_rev_id=prompt_rev_id,\n",
    "                                  #llm_model=\"bedrock/anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "                                  #llm_model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "                                  llm_model=\"groq/deepseek-r1-distill-llama-70b\",\n",
    "                                  #llm_model=\"gemini/gemini-2.0-flash\",\n",
    "                                  #llm_model=\"gemini/gemini-2.5-flash-preview-05-20\",\n",
    "                                  #llm_model=\"gemini/gemini-2.5-flash-preview-tts\",\n",
    "                                  #llm_model=\"azure_ai/deepseek-v3\",\n",
    "                                  #llm_model=\"gpt-4o-mini\",\n",
    "                                  #llm_model=\"gpt-4o-2024-08-06\",\n",
    "                                  #llm_model=\"claude-3-5-sonnet\",\n",
    "                                  #llm_model=\"mistral/mistral-large-latest\",\n",
    "                                  #llm_model=\"mistral/open-mixtral-8x22b\",\n",
    "                                  force=True)\n",
    "llm_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result_id = await ad.llm.save_llm_result(analytiq_client,\n",
    "                                             document_id=document_id,\n",
    "                                             prompt_rev_id=prompt_rev_id,\n",
    "                                             llm_result=llm_result)\n",
    "llm_result_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = await ad.llm.get_llm_result(analytiq_client,\n",
    "                                         document_id=document_id,\n",
    "                                         prompt_rev_id=prompt_rev_id)\n",
    "llm_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ad.llm.delete_llm_result(analytiq_client,\n",
    "                                document_id=document_id,\n",
    "                                prompt_rev_id=prompt_rev_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ad.llm.run_llm_for_prompt_rev_ids(analytiq_client,\n",
    "                                        document_id=document_id,\n",
    "                                        prompt_rev_ids=[prompt_rev_id],\n",
    "                                        model=\"groq/deepseek-r1-distill-llama-70b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm.utils import supports_response_schema\n",
    "\n",
    "supports_response_schema(model=\"groq/deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ad.llm.list_llm_providers(analytiq_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.llm.is_chat_model(\"mistral/mistral-large-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.llm.get_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.llm.get_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ad.llm.get_supported_models():\n",
    "    if not ad.llm.is_supported_model(model):\n",
    "        raise Exception(f\"Model {model} is not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.models_by_provider.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ad.llm.providers.setup_llm_providers(analytiq_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from litellm import completion\n",
    "\n",
    "aws_keys = ad.aws.get_aws_keys(analytiq_client)\n",
    "aws_access_key_id = aws_keys[\"aws_access_key_id\"]\n",
    "aws_secret_access_key = aws_keys[\"aws_secret_access_key\"]\n",
    "aws_region_name = \"us-east-1\"\n",
    "\n",
    "response = completion(\n",
    "  #provider=\"bedrock\",\n",
    "  #model=\"bedrock/anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "  #model=\"bedrock/us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "  #model=\"bedrock/arn:aws:bedrock:us-east-1:890742589311:inference-profile/claude-sonnet-4-profile\",\n",
    "  #model=\"bedrock/anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "  #model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "  #model=\"gemini/gemini-2.0-flash\",\n",
    "  #model=\"gemini/gemini-2.5-flash-preview-05-20\",\n",
    "  model=\"gemini/gemini-2.5-pro-preview-06-05\",\n",
    "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}],\n",
    "  #response_format = {\"type\": \"json_object\"},\n",
    "  aws_access_key_id=aws_access_key_id,\n",
    "  aws_secret_access_key=aws_secret_access_key,\n",
    "  aws_region_name=aws_region_name,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "from litellm import CustomLLM, completion, get_llm_provider\n",
    "\n",
    "\n",
    "class MyCustomLLM(CustomLLM):\n",
    "    def completion(self, *args, **kwargs) -> litellm.ModelResponse:\n",
    "        return litellm.completion(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Hello world\"}],\n",
    "            mock_response=\"Hi!\",\n",
    "        )  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_custom_llm = MyCustomLLM()\n",
    "\n",
    "litellm.custom_provider_map = [ # 👈 KEY STEP - REGISTER HANDLER\n",
    "        {\"provider\": \"my-custom-llm\", \"custom_handler\": my_custom_llm}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = completion(\n",
    "        model=\"my-custom-llm/my-fake-model\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Hello world!\"}],\n",
    "    )\n",
    "\n",
    "assert resp.choices[0].message.content == \"Hi!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
