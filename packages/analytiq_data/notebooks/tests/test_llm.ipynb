{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import analytiq_data as ad\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.common.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MONGODB_URI environment variable\n",
    "os.environ[\"MONGODB_URI\"] = \"mongodb://localhost:27017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qP8xDKSfu6Ede7pbEmUWc6I6ii7sOAHr\n"
     ]
    }
   ],
   "source": [
    "analytiq_client = ad.common.get_analytiq_client(env=\"test\")\n",
    "\n",
    "llm_key = await ad.llm.get_llm_key(analytiq_client, llm_provider=\"mistral\")\n",
    "print(llm_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('67fb329275436ea808f0c0b5', 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_id = \"6795345439604beca2b2808d\"\n",
    "prompt_id, version = await ad.common.get_prompt_id_and_version(analytiq_client, \"cv\", org_id)\n",
    "prompt_id, version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6840ae34ca71c1ea380f7dd0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_rev_id = await ad.common.get_prompt_rev_id(analytiq_client, prompt_id, version)\n",
    "prompt_rev_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_rev_id = \"6840ae34ca71c1ea380f7dd0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_id = \"683ffcfce640fb757220edfe,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 01:06:58,713 - analytiq_data.llm.models - INFO - Prompt: {'_id': ObjectId('6840ae34ca71c1ea380f7dd0'), 'prompt_id': '67fb329275436ea808f0c0b5', 'content': \"Extract the candidate resume according to the specified schema.\\n\\n- Any empty elements should be reported as an empty string ''. \\n- All extraction fields are mandatory.\", 'schema_id': '67fb329175436ea808f0c0a2', 'schema_version': 5, 'prompt_version': 9, 'created_at': datetime.datetime(2025, 6, 4, 20, 36, 4, 237000), 'created_by': '679533ee39604beca2b2803a', 'tag_ids': ['67ce42b43fe8e757f213f498'], 'model': 'claude-3-7-sonnet-latest'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'claude-3-7-sonnet-latest'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await ad.llm.get_llm_model(analytiq_client, prompt_rev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 01:07:52,297 - analytiq_data.llm.llm - INFO - Running new LLM analysis for document_id: 683ffcfce640fb757220edfe,, prompt_rev_id: 6840ae34ca71c1ea380f7dd0\n",
      "2025-06-05 01:07:52,298 - analytiq_data.llm.llm - INFO - LLM model: gpt-4o-mini, provider: openai, api_key: sk-proj-zpkpvJum********\n",
      "2025-06-05 01:07:52,301 - analytiq_data.llm.llm - INFO - Response format: {'type': 'json_schema', 'json_schema': {'name': 'document_extraction', 'schema': {'type': 'object', 'properties': {'demographics': {'type': 'object', 'properties': {'first_name': {'type': 'string', 'description': 'Candidate first name'}, 'last_name': {'type': 'string', 'description': 'Candidate last name'}, 'address': {'type': 'string', 'description': 'Candidate address.'}, 'linkedin_url': {'type': 'string', 'description': 'The LinkedIn URL, which could be of the form linkedin.com/<user>'}}, 'additionalProperties': False, 'required': ['first_name', 'last_name', 'address', 'linkedin_url'], 'description': 'Demographics'}, 'programming_languages': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Programming languages the candidate is able to program in'}, 'spoken_languages': {'type': 'array', 'items': {'type': 'string'}, 'description': 'spoken languages'}}, 'required': ['demographics', 'programming_languages', 'spoken_languages'], 'additionalProperties': False}, 'strict': True}}\n",
      "\u001b[92m01:07:52 - LiteLLM:INFO\u001b[0m: utils.py:2826 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "2025-06-05 01:07:52,313 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "2025-06-05 01:07:53,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m01:07:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "2025-06-05 01:07:53,621 - LiteLLM - INFO - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m01:07:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "2025-06-05 01:07:53,622 - LiteLLM - INFO - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "2025-06-05 01:07:53,624 - analytiq_data.llm.llm - INFO - Saving LLM result: {'prompt_rev_id': '6840ae34ca71c1ea380f7dd0', 'document_id': '683ffcfce640fb757220edfe,', 'llm_result': {'demographics': {'first_name': '', 'last_name': '', 'address': '', 'linkedin_url': ''}, 'programming_languages': [], 'spoken_languages': []}, 'updated_llm_result': {'demographics': {'first_name': '', 'last_name': '', 'address': '', 'linkedin_url': ''}, 'programming_languages': [], 'spoken_languages': []}, 'is_edited': False, 'is_verified': False, 'created_at': datetime.datetime(2025, 6, 5, 5, 7, 53, 624340, tzinfo=datetime.timezone.utc), 'updated_at': datetime.datetime(2025, 6, 5, 5, 7, 53, 624340, tzinfo=datetime.timezone.utc)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'demographics': {'first_name': '',\n",
       "  'last_name': '',\n",
       "  'address': '',\n",
       "  'linkedin_url': ''},\n",
       " 'programming_languages': [],\n",
       " 'spoken_languages': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result = await ad.llm.run_llm(analytiq_client,\n",
    "                                  document_id=document_id,\n",
    "                                  prompt_rev_id=prompt_rev_id,\n",
    "                                  #llm_model=\"groq/deepseek-r1-distill-llama-70b\",\n",
    "                                  #llm_model=\"gemini/gemini-2.0-flash\",\n",
    "                                  #llm_model=\"gpt-4o-mini\",\n",
    "                                  #llm_model=\"gpt-4o\",\n",
    "                                  #llm_model=\"claude-3-5-sonnet\",\n",
    "                                  #llm_model=\"mistral/mistral-large-latest\",\n",
    "                                  #llm_model=\"mistral/open-mixtral-8x22b\",\n",
    "                                  force=True)\n",
    "llm_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result_id = await ad.llm.save_llm_result(analytiq_client,\n",
    "                                             document_id=document_id,\n",
    "                                             prompt_rev_id=prompt_rev_id,\n",
    "                                             llm_result=llm_result)\n",
    "llm_result_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = await ad.llm.get_llm_result(analytiq_client,\n",
    "                                         document_id=document_id,\n",
    "                                         prompt_rev_id=prompt_rev_id)\n",
    "llm_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ad.llm.delete_llm_result(analytiq_client,\n",
    "                                document_id=document_id,\n",
    "                                prompt_rev_id=prompt_rev_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ad.llm.run_llm_for_prompt_rev_ids(analytiq_client,\n",
    "                                        document_id=document_id,\n",
    "                                        prompt_rev_ids=[prompt_rev_id],\n",
    "                                        model=\"groq/deepseek-r1-distill-llama-70b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm.utils import supports_response_schema\n",
    "\n",
    "supports_response_schema(model=\"groq/deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ad.llm.list_llm_providers(analytiq_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ad.llm.providers.setup_llm_providers(analytiq_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
